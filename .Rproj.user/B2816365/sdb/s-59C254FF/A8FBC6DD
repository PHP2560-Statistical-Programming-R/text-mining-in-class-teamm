{
    "collab_server" : "",
    "contents" : "Text Analysis\n================\n\nYour mission\n============\n\nPerform text analysis.\n\nOkay, I need more information\n-----------------------------\n\nPerform sentiment analysis or topic modeling using text analysis methods as demonstrated in the pre-class work and in the readings.\n\nOkay, I need even more information.\n-----------------------------------\n\nDo the above. Can't think of a data source?\n\n-   `gutenbergr`\n-   `AssociatedPress` from the `topicmodels` package\n-   `NYTimes` or `USCongress` from the `RTextTools` package\n-   Harry Potter Complete 7 Books text \\`\\`\\` if (packageVersion(\"devtools\") &lt; 1.6) { install.packages(\"devtools\") }\n\ndevtools::install\\_github(\"bradleyboehmke/harrypotter\") \\`\\``- [State of the Union speeches](https://pradeepadhokshaja.wordpress.com/2017/03/31/scraping-the-web-for-presdential-inaugural-addresses-using-rvest/) - Scrape tweets using [`twitteR\\`\\](<https://www.credera.com/blog/business-intelligence/twitter-analytics-using-r-part-1-extract-tweets/>)\n\nAnalyze the text for sentiment OR topic. **You do not need to do both**. The datacamp courses and [Tidy Text Mining with R](http://tidytextmining.com/) are good starting points for templates to perform this type of analysis, but feel free to *expand beyond these examples*.\n\nTimelines and Task\n==================\n\nWe will spend the next 2 weeks working on analyzing textual data in R. You will do the following:\n\n-   Start with some text based data.\n-   Clean data and prepare it for analysis\n-   Ask questions about the data\n-   Answer these questions with the data using tables and graphics\n-   Each group member must have their own unique question that they code the answer for.\n\nSET UP\n------\n\n``` r\n# Get libraries\nlibrary(tidytext)\n```\n\n    ## Warning: package 'tidytext' was built under R version 3.4.2\n\n``` r\nlibrary(dplyr)\n```\n\n    ## Warning: package 'dplyr' was built under R version 3.4.1\n\n    ## \n    ## Attaching package: 'dplyr'\n\n    ## The following objects are masked from 'package:stats':\n    ## \n    ##     filter, lag\n\n    ## The following objects are masked from 'package:base':\n    ## \n    ##     intersect, setdiff, setequal, union\n\n``` r\nlibrary(rebus)\nlibrary(stringr)\n```\n\n    ## \n    ## Attaching package: 'stringr'\n\n    ## The following object is masked from 'package:rebus':\n    ## \n    ##     regex\n\n``` r\nlibrary(ggplot2)\n```\n\n    ## \n    ## Attaching package: 'ggplot2'\n\n    ## The following object is masked from 'package:rebus':\n    ## \n    ##     alpha\n\nPrepare Titles and Sentiment Scores\n-----------------------------------\n\n``` r\n# Get Data\nlibrary(RTextTools)\n```\n\n    ## Loading required package: SparseM\n\n    ## \n    ## Attaching package: 'SparseM'\n\n    ## The following object is masked from 'package:base':\n    ## \n    ##     backsolve\n\n``` r\ndata(NYTimes)\n\n\n# Get dictionary with sentiment scores using lexicon afinn \nsentiment.scores = as.data.frame(get_sentiments(\"afinn\"))\n\n# Prepare the titles as strings by converting title to characters\nNYTimes$title = (as.character(NYTimes$Title))\n```\n\nSentiments of NY Times Titles\n=============================\n\nIntensity of Negative and Positive Words in NY Times Titles\n-----------------------------------------------------------\n\nThis section looks at what the frequency distribution of the intensity of negative and positive words used in the NY Times titles are.\n\n``` r\n# Create a data frame that will contain the sentiment scores for each word in the title\nscores = NYTimes %>%\n  # group the data by title\n  group_by(Title) %>%\n  # get each word from the title out by unnesting\n  unnest_tokens(output=word, input=title) %>%\n  # get the sentiment scores for each word in the title \n  inner_join(sentiment.scores) %>%\n  # get a mean of the score for each word in the title to get an average sentiment score for each title \n  summarize(title.score = mean(score))\n```\n\n    ## Joining, by = \"word\"\n\n``` r\n# plot mean scores for each title \n\nggplot(scores,aes(title.score)) + \n  labs(x = \"Mean Score\") +\n  geom_histogram(color=\"black\",fill=\"lightblue1\",aes(y=..density..), binwidth=1) +\n  geom_density() + \n  scale_x_continuous(breaks = pretty(scores$title.score, n = 10)) +\n  ggtitle(\"NY Times Title Mean Sentiment Scores Distribution\") +\n  theme(plot.title = element_text(color=\"black\", face=\"bold\", size=18,hjust = 0.5)) +\n  #theme_bw() + \n  theme(panel.border = element_blank(), panel.grid.major = element_blank(),\n        panel.grid.minor = element_blank(), axis.line = element_line(colour = \"black\")) +\n theme(panel.background = element_rect(fill='white')) +\n  theme(axis.text.x = element_text(colour=\"grey20\",size=12,angle=45,hjust=.5,vjust=.5,face=\"plain\"),\n        axis.text.y = element_text(colour=\"grey20\",size=12,angle=0,hjust=1,vjust=0,face=\"plain\"),  \n        axis.title.x = element_text(colour=\"grey20\",size=15,angle=0,hjust=.5,vjust=0,face=\"plain\"),\n        axis.title.y = element_text(colour=\"grey20\",size=15,angle=90,hjust=.5,vjust=.5,face=\"plain\"))\n```\n\n![](text_mining_-_AX_files/figure-markdown_github-ascii_identifiers/unnamed-chunk-3-1.png)\n\nThis plot shows the frequency of the mean intensities of positive/negative words used in the titles. A higher absolute value indicates greater intensity of an emotion in words for the title, whereas a lower one indicates less intensity. Negative numbers indicate negative emotions whereas positive numbers indicate positive emotions.\n\nExtremeness of Emotional Words Used in NY Times Titles\n------------------------------------------------------\n\nThis section looks at just how intense the emotions of the words in NY Times titles are (i.e., it doesn't matter whether the emotions are negative or positive; we are just interested in how extreme these emotions get).\n\n``` r\n# We do the same thing as Part 1a except now, if the scores are negative, we get the absolute value of them.\n\n# Create a data frame that will contain the sentiment scores for each word in the title\nscores = NYTimes %>%\n  # group the data by title\n  group_by(Title) %>%\n  # get each word from the title out by unnesting\n  unnest_tokens(output=word, input=title) %>%\n  # get the sentiment scores for each word in the title \n  inner_join(sentiment.scores) %>%\n  # get the absolute value of the sentiment scores so that we get the intensity score\n  mutate(intensity.score = abs(score))\n```\n\n    ## Joining, by = \"word\"\n\n``` r\n# get a mean of the intensity for each titles \nscores = scores %>% \n  group_by(Title) %>%\n  summarize(title.intensity.score = mean(intensity.score))\n\n# plot mean scores for each title \nggplot(scores,aes(title.intensity.score)) + \n  # label the x-axis \n  labs(x = \"Intensity Score\") +\n  # create histogram with a density curve\n  geom_histogram(color=\"black\",fill=\"indianred2\",aes(y=..density..), binwidth=0.5) +\n  geom_density() + \n  # label the x-axis tick marks in a way that's intuitive\n  scale_x_continuous(breaks = pretty(scores$title.intensity.score, n = 10)) +\n  # make the title nice\n  ggtitle(\"NY Times Title Mean Intensity Scores Distribution\") +\n  theme(plot.title = element_text(color=\"black\", face=\"bold\", size=18,hjust = 0.5)) +\n  # get the background to be white and get rid of the grid marks\n  theme(panel.border = element_blank(), panel.grid.major = element_blank(),\n        panel.grid.minor = element_blank(), axis.line = element_line(colour = \"black\")) +\n theme(panel.background = element_rect(fill='white')) +\n  # make the axis tick marks and text look nicer \n  theme(axis.text.x = element_text(colour=\"grey20\",size=12,angle=45,hjust=.5,vjust=.5,face=\"plain\"),\n        axis.text.y = element_text(colour=\"grey20\",size=12,angle=0,hjust=1,vjust=0,face=\"plain\"),  \n        axis.title.x = element_text(colour=\"grey20\",size=15,angle=0,hjust=.5,vjust=0,face=\"plain\"),\n        axis.title.y = element_text(colour=\"grey20\",size=15,angle=90,hjust=.5,vjust=.5,face=\"plain\"))\n```\n\n![](text_mining_-_AX_files/figure-markdown_github-ascii_identifiers/unnamed-chunk-4-1.png)\n\nHow is it different by time?\n\n``` r\n############# Get years\n\n#1. Convert Dates to Strings\n\n# make the date as characters\nNYTimes$Date = as.character(NYTimes$Date)\n\n# now convert the date to strings\nfor (i in 1:length(NYTimes$Date)){\nNYTimes$Date[i] = toString(NYTimes$Date[i])\n}\n\n#2. Extract the Year\n# create a pattern for how the year will look like\nyear_pattern = DGT %R% DGT %R% END\n# get the year using this pattern and put this year in our data frame with scores\nNYTimes$year = str_extract(NYTimes$Date, pattern=year_pattern)\n\n# now, create a new data frame that will contain the sentiment scores for titles by year\n\n# first, get the mean sentiment scores for each title\nscores2 = \nNYTimes %>% \n  group_by(Title, year) %>%\n   # get each word from the title out by unnesting\n  unnest_tokens(output=word, input=title) %>%\n  # get the sentiment scores for each word in the title \n  inner_join(sentiment.scores) %>%\n  # mean score\n  summarize(title.score = mean(score))\n```\n\n    ## Joining, by = \"word\"\n\n``` r\n# now, group by year so that we get a mean sentiment score for each year  \nscores2 =\n  scores2 %>%\n  group_by(year) %>%\n  summarize(year.score = mean(title.score))\n\n# create a new data frame to get the absolute value for each year so that we get intensity scores\n\nscores3 = \n  scores2 %>% \n  mutate(year.intensity = abs(year.score))\n\n# change the years to be numeric\nscores2$year = (as.numeric(scores2$year))\n\n# change the years to be from year 1 to year 10 by making 1996 as year 1 and 2006 as year 10 \nscores2 = scores2 %>% \n  mutate(year.num = ifelse(scores2$year<=6, 10-scores2$year, abs(96-scores2$year)))\nscores3$year.num = scores2$year.num\n\n# LINE PLOTS\n\n# This plots the sentiment scores\nggplot(data=scores2, aes(x=year.num,y=year.score)) +\n  geom_line(color=\"steelblue4\", linetype=\"dashed\") +\n  labs(x = \"Year\", y = \"Mean Score\") +\n  scale_x_continuous(breaks = pretty(scores2$year.num, n = 10),labels=c(1996:2006)) +\n  scale_y_continuous(breaks = pretty(scores2$year.score, n = 8)) +\n  geom_point(size=3,color=\"steelblue4\") +\n  ggtitle(\"NY Times Mean Title Sentiment Scores Over Time\") +\n  theme(plot.title = element_text(color=\"black\", face=\"bold\", size=18,hjust = 0.5)) +\n  #theme_bw() + \n  theme(panel.border = element_blank(), panel.grid.major = element_blank(),\n        panel.grid.minor = element_blank(), axis.line = element_line(colour = \"black\")) +\n  theme(panel.background = element_rect(fill='white')) +\n      theme(axis.text.x = element_text(colour=\"grey20\",size=12,angle=0,hjust=.5,vjust=.5,face=\"plain\"),\n        axis.text.y = element_text(colour=\"grey20\",size=12,angle=0,hjust=1,vjust=0,face=\"plain\"),  \n        axis.title.x = element_text(colour=\"grey20\",size=15,angle=0,hjust=.5,vjust=0,face=\"plain\"),\n        axis.title.y = element_text(colour=\"grey20\",size=15,angle=90,hjust=.5,vjust=.5,face=\"plain\"))\n```\n\n![](text_mining_-_AX_files/figure-markdown_github-ascii_identifiers/unnamed-chunk-5-1.png)\n\n``` r\n# This plots the intensity scores\nggplot(data=scores3, aes(x=year.num,y=year.intensity)) +\n  geom_line(color=\"firebrick3\", linetype=\"dashed\") +\n  labs(x = \"Year\", y = \"Mean Intensity\") +\n  scale_x_continuous(breaks = pretty(scores3$year.num, n = 10),labels=c(1996:2006)) +\n  scale_y_continuous(breaks = pretty(scores3$year.intensity, n = 8)) +\n  geom_point(size=3,color=\"firebrick3\") +\n  ggtitle(\"NY Times Mean Title Sentiment Intensity Over Time\") +\n  theme(plot.title = element_text(color=\"black\", face=\"bold\", size=18,hjust = 0.5)) +\n  #theme_bw() + \n  theme(panel.border = element_blank(), panel.grid.major = element_blank(),\n        panel.grid.minor = element_blank(), axis.line = element_line(colour = \"black\")) +\n  theme(panel.background = element_rect(fill='white')) +\n      theme(axis.text.x = element_text(colour=\"grey20\",size=12,angle=0,hjust=.5,vjust=.5,face=\"plain\"),\n        axis.text.y = element_text(colour=\"grey20\",size=12,angle=0,hjust=1,vjust=0,face=\"plain\"),  \n        axis.title.x = element_text(colour=\"grey20\",size=15,angle=0,hjust=.5,vjust=0,face=\"plain\"),\n        axis.title.y = element_text(colour=\"grey20\",size=15,angle=90,hjust=.5,vjust=.5,face=\"plain\"))\n```\n\n![](text_mining_-_AX_files/figure-markdown_github-ascii_identifiers/unnamed-chunk-5-2.png)\n",
    "created" : 1508681907813.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "3532614306",
    "id" : "A8FBC6DD",
    "lastKnownWriteTime" : 1508951436,
    "last_content_update" : 1508951436430,
    "path" : "~/text-mining-in-class-teamm/text_mining_-_AX.md",
    "project_path" : "text_mining_-_AX.md",
    "properties" : {
    },
    "relative_order" : 2,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "markdown"
}